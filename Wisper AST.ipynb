{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d34f52b8-7412-43a9-8367-f8e20da19a95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to c:\\users\\hp\\appdata\\local\\temp\\pip-req-build-tc_mf3gw\n",
      "  Resolved https://github.com/huggingface/transformers to commit 4b236aed7618d90546cd2e8797dab5b4a24c5dce\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.38.0.dev0) (3.13.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from transformers==4.38.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.0.dev0)\n",
      "  Downloading tokenizers-0.15.1-cp39-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.38.0.dev0)\n",
      "  Downloading safetensors-0.4.2-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.38.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from tqdm>=4.27->transformers==4.38.0.dev0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers==4.38.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers==4.38.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers==4.38.0.dev0) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->transformers==4.38.0.dev0) (2023.7.22)\n",
      "Downloading safetensors-0.4.2-cp39-none-win_amd64.whl (269 kB)\n",
      "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/269.7 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/269.7 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 61.4/269.7 kB 648.1 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 245.8/269.7 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 269.7/269.7 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.15.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 13.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.2 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.7/2.2 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 7.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): still running...\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8457594 sha256=05c4756c6994e5099fd928b6abe069508bc9825c34e90cca6268a83065b1fe8b\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-u2bbghz5\\wheels\\14\\a0\\7b\\8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "  Attempting uninstall: safetensors\n",
      "    Found existing installation: safetensors 0.4.0\n",
      "    Uninstalling safetensors-0.4.0:\n",
      "      Successfully uninstalled safetensors-0.4.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.0\n",
      "    Uninstalling transformers-4.30.0:\n",
      "      Successfully uninstalled transformers-4.30.0\n",
      "Successfully installed safetensors-0.4.2 tokenizers-0.15.1 transformers-4.38.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers 'C:\\Users\\HP\\AppData\\Local\\Temp\\pip-req-build-tc_mf3gw'\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\anaconda3\\envs\\LLM\\Lib\\site-packages\\~afetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\anaconda3\\envs\\LLM\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.24.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from librosa) (1.0.7)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pooch>=1.0->librosa) (2.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pooch>=1.0->librosa) (23.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.7.22)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.6.1-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from click<9.0.0,>=8.1.3->jiwer) (0.4.6)\n",
      "Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n",
      "Downloading rapidfuzz-3.6.1-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.6 MB 1.7 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.2/1.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.0/1.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.5/1.6 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-3.0.3 rapidfuzz-3.6.1\n",
      "Collecting gradio\n",
      "  Downloading gradio-4.17.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (4.2.2)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==0.9.0 (from gradio)\n",
      "  Downloading gradio_client-0.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx (from gradio)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (0.20.3)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (3.6.3)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (1.24.1)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.9.13-cp39-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.6/50.6 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (1.5.2)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (2.4.2)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio)\n",
      "  Downloading python_multipart-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (6.0)\n",
      "Collecting ruff>=0.1.7 (from gradio)\n",
      "  Downloading ruff-0.2.1-py3-none-win_amd64.whl.metadata (23 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9->gradio)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from gradio-client==0.9.0->gradio) (2023.10.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.9.0->gradio)\n",
      "  Downloading websockets-11.0.3-cp39-cp39-win_amd64.whl (124 kB)\n",
      "     ---------------------------------------- 0.0/124.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 124.7/124.7 kB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from pydantic>=2.0->gradio) (2.10.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx->gradio) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx->gradio)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (1.26.13)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\envs\\llm\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
      "Downloading gradio-4.17.0-py3-none-any.whl (16.7 MB)\n",
      "   ---------------------------------------- 0.0/16.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/16.7 MB 11.6 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.7/16.7 MB 9.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.3/16.7 MB 10.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.6/16.7 MB 9.2 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.6/16.7 MB 8.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.6/16.7 MB 8.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.7/16.7 MB 5.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 2.0/16.7 MB 5.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.5/16.7 MB 6.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/16.7 MB 6.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/16.7 MB 6.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/16.7 MB 6.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/16.7 MB 6.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.4/16.7 MB 5.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 4.1/16.7 MB 5.8 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.4/16.7 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.8/16.7 MB 6.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 5.0/16.7 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.2/16.7 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.4/16.7 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.4/16.7 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.8/16.7 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.0/16.7 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.0/16.7 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 6.2/16.7 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.4/16.7 MB 5.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.5/16.7 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.7/16.7 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.9/16.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 7.0/16.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 7.0/16.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.3/16.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.4/16.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.5/16.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.6/16.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.7/16.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.8/16.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.9/16.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.0/16.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.2/16.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 8.3/16.7 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.5/16.7 MB 4.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.6/16.7 MB 4.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.7/16.7 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.9/16.7 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 9.0/16.7 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 9.1/16.7 MB 4.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 9.2/16.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.3/16.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.4/16.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 9.6/16.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.7/16.7 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.7/16.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.9/16.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 10.0/16.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.2/16.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.3/16.7 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 10.4/16.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.5/16.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.6/16.7 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.7/16.7 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.8/16.7 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 10.9/16.7 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 11.0/16.7 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 11.2/16.7 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.3/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.5/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 11.6/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 11.8/16.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 12.0/16.7 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 12.1/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 12.4/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 12.5/16.7 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.7/16.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 12.9/16.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 13.0/16.7 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 13.2/16.7 MB 3.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 13.4/16.7 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.6/16.7 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.8/16.7 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.0/16.7 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 14.2/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.4/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 14.5/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.9/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.1/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 15.3/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.5/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.9/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 16.1/16.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.3/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.5/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  16.7/16.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 16.7/16.7 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading gradio_client-0.9.0-py3-none-any.whl (306 kB)\n",
      "   ---------------------------------------- 0.0/306.8 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 204.8/306.8 kB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 306.8/306.8 kB 3.8 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading orjson-3.9.13-cp39-none-win_amd64.whl (134 kB)\n",
      "   ---------------------------------------- 0.0/134.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 134.0/134.0 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading ruff-0.2.1-py3-none-win_amd64.whl (7.4 MB)\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.4 MB 8.3 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.5/7.4 MB 6.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/7.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.9/7.4 MB 5.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.1/7.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.3/7.4 MB 5.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.5/7.4 MB 4.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.8/7.4 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.4 MB 4.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.2/7.4 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.4 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.7/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.9/7.4 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.1/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.3/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.5/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.8/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.0/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.3/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.5/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.8/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.0/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.2/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.5/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.7/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.9/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.1/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.4/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.6/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.9/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.1/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.4/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.4/7.4 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.4/7.4 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
      "   ---------------------------------------- 0.0/60.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 60.7/60.7 kB 3.2 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
      "   ---------------------------------------- 0.0/92.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 92.1/92.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "   ---------------------------------------- 0.0/75.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 75.9/75.9 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.9/76.9 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.7-py3-none-any.whl (22 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.5/71.5 kB 3.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5601 sha256=53a4207947321d49ebc4ae818cb4e81df94aa02022f9bfc6acacf227c426fae6\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\1f\\f1\\8d\\367922b023b526b7c2ced5db30932def7b18cf39d7ac6e8572\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, importlib-resources, h11, uvicorn, typer, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
      "Successfully installed fastapi-0.109.2 ffmpy-0.3.1 gradio-4.17.0 gradio-client-0.9.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 importlib-resources-6.1.1 orjson-3.9.13 pydub-0.25.1 python-multipart-0.0.7 ruff-0.2.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 typer-0.9.0 uvicorn-0.27.0.post1 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=2.6.1\n",
    "!pip install git+https://github.com/huggingface/transformers\n",
    "!pip install librosa\n",
    "!pip install evaluate>=0.30\n",
    "!pip install jiwer\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0393d4b6-5a2d-4097-9db1-5f5a5e6040b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df028b32-91f0-453a-a083-666fa0881b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4e7503084742e9bd90ae2fe74c7d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\LLM\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--openai--whisper-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067da882701437d9a454e13110fa048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca80fa6d89284b06a51ba339baba47e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1cb01dd1fa489bb5bcfe632b3101cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049518f7ad934774acbbbad9fdc44a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a0f755b7847b09abe411f87ca87a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4540d2c188b24c38b20d4ba28e8a0c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a8e6f1f500492f96aa3695e8f122ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f5a64ab99344c6922281ca9e72fabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef541908001435ea26dc4c167246832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a69606b5c0847fe9e18d962052a7a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"openai/whisper-base\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d3b7f81-d8c4-4ef5-9dfa-0dc448c9c914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4c2f646-818c-4585-8d0d-1338288ea975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c797e415-dad5-4c8d-bbbe-fe5a5635d5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d349214e-21eb-44c3-a66b-dfab45175acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "        0.0005188 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8a3cd49-0dc9-434d-b4f0-b77cb0967bf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly he's drawn from eating and its results occur most readily to the mind. He has graved doubts whether Sir Frederick Layton's work is really Greek after all, and can discover in it but little of Rocky Ithaca. Lynelle's pictures are a sort of upgards and atom paintings, and Mason's exquisite ittles are as national as a jingo poem. Mr. Birk at Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says like a shampoo in a Turkish bath. Next man,\n"
     ]
    }
   ],
   "source": [
    "result = pipe(sample, generate_kwargs={\"language\": \"english\"})\n",
    "\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80d46c-ae9f-4f49-adc0-f177705ad46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3296b5d2-214d-4f28-bcaf-ae1352ba7842",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since lj_speech couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'main' at C:\\Users\\HP\\.cache\\huggingface\\datasets\\lj_speech\\main\\1.1.0\\af8fa32e4f43a1251b5a2d9cc121181d66575939 (last modified on Wed Feb  7 14:45:53 2024).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'audio', 'file', 'text', 'normalized_text'],\n",
      "        num_rows: 1310\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"lj_speech\",split='train[:10%]', use_auth_token=True)\n",
    "#common_voice[\"validation\"] = load_dataset(\"lj_speech\",  split=\"validation\", use_auth_token=True)\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66d866da-7eb8-4bf7-aeb0-78e091bfa7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5033860-3d23-4d7a-9235-f9f206371978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8d2bbdf2a940ab9e460b5d796c8014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b88cdbc642a4e4db072e8fd179c8447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ff0976fd5b42079cad2cd3d7b7fc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec91be7c7c04aceb60cc51c2cef9bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb5470fec448809b27e73861c144b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe4d67bc3094fc3ab6fdd1c20d02c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aeefd52dcc4bd3a9db25e66737702e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d50aedcd-3a64-48f9-a03f-bd4e1e990ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, Trainer, TrainingArguments\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c58a9-df6d-467c-9e78-bc597f62501d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd6a7a18-2b0e-45af-873e-c6e68d66ab2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'LJ001-0001', 'audio': {'path': 'LJ001-0001.wav', 'array': array([-7.32421875e-04, -7.62939453e-04, -6.40869141e-04, ...,\n",
      "        7.32421875e-04,  2.13623047e-04,  6.10351562e-05]), 'sampling_rate': 22050}, 'file': '/storage/hf-datasets-cache/heavy/datasets/99585803243503-config-parquet-and-info-lj_speech-4e2d0af0/downloads/extracted/034012ae2b5e0aa215c21354dfc93ab72d895d00717e088a2affe73ee49d0b98/LJSpeech-1.1/wavs/LJ001-0001.wav', 'text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', 'normalized_text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3fef3b8-2033-4aa5-9033-4bd3eb5f2781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52ad3d51-f90c-4f38-abb5-a71e4e27925d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'LJ001-0001', 'audio': {'path': 'LJ001-0001.wav', 'array': array([-0.00061751, -0.00074496, -0.00068972, ...,  0.00068615,\n",
      "        0.00013802,  0.        ]), 'sampling_rate': 16000}, 'file': '/storage/hf-datasets-cache/heavy/datasets/99585803243503-config-parquet-and-info-lj_speech-4e2d0af0/downloads/extracted/034012ae2b5e0aa215c21354dfc93ab72d895d00717e088a2affe73ee49d0b98/LJSpeech-1.1/wavs/LJ001-0001.wav', 'text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition', 'normalized_text': 'Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition'}\n"
     ]
    }
   ],
   "source": [
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f512888-a08e-4a6a-ae76-80654fa2d2b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_1516\\601695158.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"wer\")\n",
      "C:\\Users\\HP\\anaconda3\\envs\\LLM\\lib\\site-packages\\datasets\\load.py:752: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f3df6174be4984bf3222c40fd2cd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import torch\n",
    "\n",
    "metric = load_metric(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # We do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a093c8cc-8f1f-4a89-9cf7-ffdeadd6e8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\HP\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\pytorch_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\utils\\import_utils.py:1084\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m PYTORCH_QUANTIZATION_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m-> 1084\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the pytorch-quantization library but it was not found in your environment. You can install it with pip:\u001b[39m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124m`pip install pytorch-quantization --extra-index-url https://pypi.ngc.nvidia.com`\u001b[39m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;124mPlease note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\trainer.py:67\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adafactor, get_scheduler\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL_LAYERNORM_LAYERS, is_torch_greater_or_equal_than_1_13\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizerBase\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\HP\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\pytorch_utils.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WhisperProcessor, Trainer, TrainingArguments\n\u001b[0;32m      3\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      4\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\utils\\import_utils.py:1074\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m FTFY_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the ftfy library but it was not found in your environment. Checkout the instructions on the\u001b[39m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;124minstallation section: https://github.com/rspeer/python-ftfy/tree/master#installing and follow the ones\u001b[39m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;124mthat match your environment. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1069\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1071\u001b[0m LEVENSHTEIN_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the python-Levenshtein library but it was not found in your environment. You can install it with pip: `pip\u001b[39m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;124minstall python-Levenshtein`. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[1;32m-> 1074\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m G2P_EN_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the g2p-en library but it was not found in your environment. You can install it with pip:\u001b[39m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;124m`pip install g2p-en`. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\utils\\import_utils.py:1086\u001b[0m, in \u001b[0;36m_get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1077\u001b[0m G2P_EN_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the g2p-en library but it was not found in your environment. You can install it with pip:\u001b[39m\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;124m`pip install g2p-en`. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m PYTORCH_QUANTIZATION_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the pytorch-quantization library but it was not found in your environment. You can install it with pip:\u001b[39m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;124m`pip install pytorch-quantization --extra-index-url https://pypi.ngc.nvidia.com`\u001b[39m\n\u001b[1;32m-> 1086\u001b[0m \u001b[38;5;124mPlease note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# docstyle-ignore\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m TENSORFLOW_PROBABILITY_IMPORT_ERROR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m requires the tensorflow_probability library but it was not found in your environment. You can install it with pip as\u001b[39m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;124mexplained here: https://github.com/tensorflow/probability. Please note that you may need to restart your runtime after installation.\u001b[39m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'is_torch_greater_or_equal_than_1_13' from 'transformers.pytorch_utils' (C:\\Users\\HP\\anaconda3\\envs\\LLM\\lib\\site-packages\\transformers\\pytorch_utils.py)"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    save_total_limit=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d3783-5db8-4ad0-8816-bf5c0f672f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    #eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296e6db-0fdc-42c5-8a4b-47b7e6e08d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28349075-68cc-4923-8774-52438f6d5beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d686d050-14cd-4f99-8cf8-d4bcc5b46407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
